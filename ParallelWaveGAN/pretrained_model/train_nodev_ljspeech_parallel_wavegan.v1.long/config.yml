allow_cache: false
batch_max_steps: 20000
batch_size: 8
config: conf/parallel_wavegan.v1.long.yaml
dev_dumpdir: dump/dev/norm
dev_feats_scp: null
dev_segments: null
dev_wav_scp: null
discriminator_grad_norm: 1
discriminator_optimizer_params:
  eps: 1.0e-06
  lr: 5.0e-05
  weight_decay: 0.0
discriminator_params:
  bias: true
  conv_channels: 64
  in_channels: 1
  kernel_size: 3
  layers: 10
  nonlinear_activation: LeakyReLU
  nonlinear_activation_params:
    negative_slope: 0.2
  out_channels: 1
  use_weight_norm: true
discriminator_scheduler_params:
  gamma: 0.5
  step_size: 200000
discriminator_train_start_steps: 100000
distributed: false
eval_interval_steps: 1000
fft_size: 800
fmax: 7600
fmin: 80
format: hdf5
generator_grad_norm: 10
generator_optimizer_params:
  eps: 1.0e-06
  lr: 0.0001
  weight_decay: 0.0
generator_params:
  aux_channels: 80
  aux_context_window: 2
  dropout: 0.0
  gate_channels: 128
  in_channels: 1
  kernel_size: 3
  layers: 30
  out_channels: 1
  residual_channels: 64
  skip_channels: 64
  stacks: 3
  upsample_net: ConvInUpsampleNetwork
  upsample_params:
    upsample_scales:
    - 2
    - 5
    - 2
    - 5
    - 2
  use_weight_norm: true
generator_scheduler_params:
  gamma: 0.5
  step_size: 200000
global_gain_scale: 0.99
hop_size: 200
lambda_adv: 4.0
log_interval_steps: 100
num_mels: 80
num_save_intermediate_results: 4
num_workers: 4
outdir: exp/train_nodev_ljspeech_parallel_wavegan.v1.long
pin_memory: true
pretrain: ''
rank: 0
remove_short_samples: true
resume: ''
sampling_rate: 16000
save_interval_steps: 5000
stft_loss_params:
  fft_sizes:
  - 1024
  - 2048
  - 512
  hop_sizes:
  - 120
  - 240
  - 50
  win_lengths:
  - 600
  - 1200
  - 240
  window: hann_window
train_dumpdir: dump/train_nodev/norm
train_feats_scp: null
train_max_steps: 1000000
train_segments: null
train_wav_scp: null
trim_frame_size: 2048
trim_hop_size: 512
trim_silence: false
trim_threshold_in_db: 60
verbose: 1
version: 0.4.8
win_length: null
window: hann
